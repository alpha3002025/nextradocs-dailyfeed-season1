# Readme


# 목차
- [0. kafka 사용 케이스 소개](./introduce.md)
- [1. 카프카 통신 실패 시 처리 대책](./process-kafka-failure.md)
- [2. Producer Acks 설정, Consumer Offset Commit 설정](./producer-acks-and-consumer-offset-commit.md)
- [3. 중복 메시지 체크 방식](./checking-duplicated-message.md)
- [4. 날짜 별 토픽 운영](./date-pattern-topic.md)
- [5. publish-type 으로 kafka,feign 통신방식 선택](./publish-type.md)
- [`dailyfeed-kafka-support` 모듈 및 kafka 설정](./kafka-support-module.md)

<br/>
<br/>

# 소개
개인적으로는 비동기적인 작업 요청을 굳이 kafka 로만 할 수 있다고는 생각하지 않습니다. feign 으로 요청해두고 요청을 기록해둔 후, 그 요청기록을 batch 로 읽어들여서 지연된 처리를 하게 하는 것 역시 가능하다고 생각합니다. 이번 프로젝트에서는 조금은 억지로 kafka 를 도입하기는 했지만, kafka 의 주요 요소와 어렵게 여겨지는 부분들에 대해 알고있는지를 소개하기 위해 이번프로젝트에 kafka 를 도입하게 되었습니다.<br/>
<br/>

kafka 섹션에서 다뤄볼 예제의 내용을 그림으로 표현하면 다음과 같습니다.

![](./img/kafka/20251230-16-12-19-1.png)

`dailyfeed-frontend-svc` → `dailyfeed-content-svc`
- 사용자가 글 작성 요청한 것에 대해 `dailyfeed-content-svc` 로 `POST /api/posts` 요청을 수행합니다.
<br/>

(kafka publish) `dailyfeed-content-svc` → `kafka`
- 글 작성 후 저장을 수행합니다.
- 저장한 글에 대해 kafka topic 으로 `POST_CREATED` 이벤트메시지를 발행합니다. 
- 메시지의 키와 Payload 는 뒤에서 다른 문서에서 자세히 정리합니다.
- 만약 kafka 로 메시지 발송이 실패할 경우 deadletter 에 저장을 수행합니다.
- 만약 kafka 로 메시지 발송이 실패했을 때 deadletter 에 저장하는 작업도 실패할 경우에는 Exception 을 throw 해서 트랜잭션을 실패시킵니다.
- frontend 로는 `5xx` 에러가 발송되고 frontend 는 재시도를 수행하게 됩니다.
<br/>

(kafka listen) `kafka` → `dailyfeed-activity-svc` 
- `@KafkaListener` 를 통해 메시지를 리슨하고 있다가 `POST_CREATED` 이벤트에 대한 키와 Payload 가 담긴 메시지를 수신했습니다.
- `POST_CREATED` 이벤트에 대한 키와 Payload 내의 Payload 를 읽어들여서 `member_activities` 컬렉션에 멤버활동 기록 데이터로 변환해서 저장합니다.
- `POST_CREATED` 이벤트에 대한 메시지 키를 통해 중복 수신했는지를 체크해서 중복되었을 경우 저장을 하지 않으며, 저장 순간에도 중복될 경우 역시 고려해서 `upsert` 를 수행합니다.

<br/>
<br/>


# kafka 도입에 대한 개인적인 생각 
## (1) 개인적으로는 kafka 도입은 신중하게 고려해야 한다고 생각합니다.
개인적으로는 kafka 보다는  feign 기반의 API 통신을 선호하는 편입니다. 가끔 애플리케이션의 스케일아웃을 카프카로 수행하려고 하는 Worst Case 를 실무에 적용하려 하는 분들을 본적이 있지만 말리지 않았던 경험이 있습니다. 저는 kafka 도입을 고려해야 하는 환경은 다음과 같다고 생각합니다.

- (1) MSA 환경에서 특정 서비스에서 발생한 이벤트를 브로드캐스팅해야 할때 
- (2) 비동기적인 처리가 필요할때
- (3) 실시간 메시징 기반의 처리가 필요할때

(1) 의 경우에는 배치 또는 feign 으로 해결할 수 있다면 가급적 배치 또는 feign 으로 해결하는 것도 좋은 방식이라고 생각합니다. 예를 들어 주문/결제 등에 대해 알림톡을 발송하고, 광고알고리즘 영역 역시 이를 개선해야 하는 경우가 있을 수 있습니다. 다만, 이 경우는 2개의 API 를 호출하는게 카프카를 도입하려고 고민할 정도로 큰 문제는 아니기에 카프카롤 도입할 고민을 할 필요가 없다고 생각합니다. 그냥 두 건의 API 만 발송하면 되기에 feign 을 통해 해당되는 API 서비스들에 관련 이벤트를 통보해주면 됩니다.<br/>

(2) 의 경우 어떤 작업에 대한 요청을 하고 그 결과를 알지 않아도 될때를 의미합니다. '비동기'라는 의미를 비동기 스레드를 쓴다거나, 멀티스레드로 부하를 줄이는 것으로 착각하는 경우를 가끔 본적이 있습니다. '비동기'라는 것은 어떤 작업에 대한 요청의 결과를 응답받지 않고도 다음 작업을 수행하는 것을 의미합니다. 이 경우 엄청나게 부하가 큰 것이 아니라면 Database 내의 특정 테이블/컬럼에 플래그를 세팅해둔 후 배치를 통해 후처리하는 것도 좋은 선택이라고 생각합니다. 다만 이런 작업이 너무 많거나 경우의 수가 복잡해질 경우, 또는 브로드캐스팅의 구조가 될 경우 kafka 를 도입하는 것을 고려하게 될 것 같습니다.<br/>
<br/>

## (2) kafka 대신 feign 도 비동기적인 방식으로 적용 가능
feign API 통신의 경우 기본적으로는 동기적인 통신을 수행합니다. 그런데 feign 을 통한 API 통신 역시도 비동기적인 것처럼 처리할 수도 있습니다. 어떤 작업의 요청 들을 쌓아두는 feign API 에 요청을 보내서 해당 요청만 기록하고 해당 API 는 요청이 기록되었다면 200 OK 를 return 한 후, 뒷단에서는 해당 요청을 배치 등을 통해 지연된 배치 처리로 수행해서 지연된 배치 처리를 수행할수도 있기 때문입니다. 그래서 저는 정말로 필요한 상황에서만 kafka 를 도입하는 것이 추후 운영 시에 많은 인적인 소모가 적을 것 이라고 생각합니다. <br/>

feign 은 응답시에 응답코드도 다양하게 처리할 수 있고, 예외 코드도 다양하게 처리할 수 있으며, Response Header 등을 통해 다양한 처리를 수행할 수 있습니다. 또한 retry 정책 역시 지정할 수 있습니다. 애플리케이션의 레플리케이션 및 스케일아웃이 유연하게 구성될 수 있는 kubernetes 환경이 구축되어 있다면, 굳이 API 와의 비동기 통신을 위해 kafka 까지 사용해보려 고민하게 되지는 않을 것 같습니다. feign 역시도 동기적인 응답이 아닌 비동기적인 응답을 할 수 있다고 생각하기 때문입니다.<br/>
<br/>

## (3) 개인적으로 목격했던 kafka 를 잘못 사용했던 악습
실무에서 kafka 를 만능인 것처럼 홀려서 사용하는 케이스를 몇번 본적이 있었는데, 다음과 같은 케이스에 kafka 를 사용하는 것은 `Worst Case`이며, 운영비용을 올리고 장애 가능성을 높이며, 트러블 슈팅을 힘들게 하는 요소라고 생각합니다.<br/>

- (1) 배치 기반의 알림톡 발송을 kafka 기반으로 전환
- (2) 백엔드간 통신 시 부하가 많다고 느껴 kafka 기반으로 전환
<br/>

이 외에도 현업에서는 kafka 사용으로 인한 악습이 실제로 많이 있을 것으로 생각합니다. 실제 현업에서 목격한 건 위의 두 케이스였습니다. 실제로 목격했을 때 저는 아무것도 모른척 넘어가긴 했지만, (1) 의 케이스의 경우 알림톡 발송이 실패했을 때 데드레터 처리를 재귀적으로 처리해서 특정 사용자에게 메시지가 무한 발송되는 장애 케이스를 보기도 했고, 그걸 수정하면서 알림톡이 안가는 케이스도 본적이 있습니다.<br/>
<br/>

## (4) kafka 를 도입할 때 어려워지는 부분들
`kafka` 를 도입할 경우, 메시지 발송 시 통신레벨(L4)에서 보장하는 통신의 정합성 말고, 애플리케이션 레벨(L7)에서 통신이 정상적으로 수행되었음을 보장해야하고, 수신이 되었는지, 송신을 했는지 등을 체크해야하며, 경우의 수 역시 많아지기에 `kafka` 의 도입은 정말 신중하게 고려해야 한다고 생각합니다. 이런 문제 외에도 `kafka` 토픽을 어느샌가 알지도 못하는 서비스가 우후죽순으로 생기면서 토픽을 구독하는 서비스가 많아지면, 어디에 어떤 영향을 끼칠지 역시 파악이 안됩니다. 여기에 더해서 애플리케이션은 계속해서 개편 및 발전을 해나가기에 카프카 메시지의 버전 역시 계속 변하게 됩니다. 카프카 토픽을 구독하는 서비스가 많아질 때 여기에 대한 대응은 점점 어려워지게 됩니다.<br/>
<br/>

## (5) dailyfeed 프로젝트에서는
위의 이유로 `kafka` 도입은 가급적 신중하게 생각합니다. 하지만, 이번 프로젝트에서는 `kafka` 사용시 어떤 점이 취약하고, 이런 부분에 대해서 어떻게 대응하는지, `kafka` 에 대한 기본적인 개념은 있는지 등을 프로젝트를 통해서 보증을 해야겠다고 생각해서 `dailyfeed-activity-svc`, `dailyfeed-content-svc` 와 함께 `kafka`를 사용하는 예제 케이스를 만들었습니다.<br/>

이번 `dailyfeed` 프로젝트에서 사용한 `kafka` 관련 인프라 셋업, `kafka` 관련 애플리케이션 코드 들은 `season 2` 에서 다른 주제로 시작하려 계획 중인 피드 프로젝트인에서는 모두 삭제 예정입니다.<br/>
<br/>


